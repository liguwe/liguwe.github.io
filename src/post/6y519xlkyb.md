
# 6 使用生成模型进行文本分类

`#2025/12/30` `#ai` 


## 目录
<!-- toc -->
 ## 1. 特定任务模型 vs 生成模型  

**用一句话理解**：
- **之前的模型**（特定任务模型）：
	- 你问它"这是好评还是差评？"，它直接回答"1"（好评）或"0"（差评）
- **生成模型**：比如 `GPT`
	- 你问它同样的问题，它会用`完整的句子`回答你"这是一条正面评论"

**核心区别**：

```
特定任务模型：文本 → 数字（0或1）  
生成模型：文本 → 完整的文字回答  
```

如下图：

![{%}](https://www.ituring.com.cn/figures/2025/HandsonLLM/101.jpg)

>  `特定任务模型`从词元序列生成数值，而`生成模型`从词元序列生成词元序列

## 2. 📚 我们要用的两个生成模型

### 2.1. 1️⃣ **FLAN-T5**（开源模型）

**特点**：
- ✅ 免费使用
- ✅ 可以在自己电脑上运行
- ✅ 经过特殊训练，很会"听指令"

**怎么训练的**？  
- 模型先学习了大量`"指令+回答"`的例子，就像你做作业前老师给你看了很多答题示例一样。

#### 2.1.1. 附 T5 

T5（Text-to-Text Transfer Transformer，文本到文本迁移 Transformer）模型是一个有趣的模型系列，它利用了这种架构。如图下图所示，其架构与原始 Transformer 类似，将 12 个解码器和 12 个编码器堆叠在一起

![{%}|624](https://www.ituring.com.cn/figures/2025/HandsonLLM/103.jpg)

> T5 模型与原始 Transformer 模型类似，采用解码器 - 编码器架构

### 2.2. 2️⃣ **GPT-3.5（ChatGPT）**（专有模型）

**特点**：

- 💰 需要付费使用API
- ☁️ 在云端运行，不占用你的电脑
- 🎯 效果通常更好

---

## 3. 🛠️ 实战：用FLAN-T5给电影评论分类

### 3.1. **第一步：加载模型**

```python
from transformers import pipeline  

# 创建一个"文本生成器"  
pipe = pipeline(  
    model="google/flan-t5-base",  # 模型名称  
    device="cuda:0"  # 用GPU加速  
)  
```

### 3.2. **第二步：写一个好的"指令"**

这是关键！你需要清楚地告诉模型要做什么：

```python
prompt = """  
请预测下面这条电影评论是正面还是负面的：  
{评论内容}  

只回答"Positive"或"Negative"。  
"""  
```

**为什么这样写**？

- 📝 明确任务（"预测"）
- 📝 说清楚输入是什么（"电影评论"）
- 📝 限制输出格式（"只回答..."）

### 3.3. **第三步：让模型回答**

```python
评论 = "这部电影太棒了！"  
模型的回答 = pipe(prompt.format(评论内容=评论))  

print(模型的回答)  
# 输出：Positive  
```

## 4. 🎯 实战：用ChatGPT（GPT-3.5）分类

### 4.1. **区别**：不需要下载模型，通过网络调用

```python
import openai  

# 1. 设置API密钥（就像你的账号密码）  
client = openai.OpenAI(api_key="你的密钥")  

# 2. 发送请求  
response = client.chat.completions.create(  
    model="gpt-3.5-turbo",  
    messages=[  
        {"role": "system", "content": "你是一个电影评论分析助手"},  
        {"role": "user", "content": "这部电影是正面还是负面：Best movie ever!"}  
    ]  
)  

print(response.choices[0].message.content)  
```

#### 4.1.1. 附：GPT 的训练过程

OpenAI 分享了关于训练过程的大体情况，其中涉及一个重要组件，即偏好调优（preference tuning）。如下图 所示，OpenAI 首先手动创建了输入提示词（指令数据）的期望输出，并使用这些数据创建了模型的第一个版本。

![{%}|624](https://www.ituring.com.cn/figures/2025/HandsonLLM/106.jpg)

> 由指令（提示词）和输出组成的手动标注数据被用于执行微调（指令微调）

## 5. 📊 效果对比表

|模型类型|F1分数|优点|缺点|
|---|---|---|---|
|**特定任务模型**|0.80|速度快，直接输出|只能做一种任务|
|**嵌入+分类器**|0.85|性能好，灵活|需要训练数据|
|**零样本分类**|0.78|不需要训练|效果稍差|
|**FLAN-T5**|未提及|免费开源|需要本地资源|
|**GPT-3.5**|**0.91**|**效果最好**|收费，无法控制|

---

## 6. 💡 核心思想总结

### 6.1. **为什么生成模型能做分类**？

- 1️⃣ **它理解自然语言指令**  
	- 你用人话告诉它"判断这是好评还是差评"，它就能明白
- 2️⃣ **它见过大量类似例子**  
	- 训练时已经学过无数条"指令→回答"的配对
- 3️⃣ **它会用文字回答**  
	- 虽然我们只需要"好评/差评"，但它用完整句子表达更自然

### 6.2. **关键技巧**：

✅ **写清楚指令**（第6章会详细讲提示工程）  
✅ **限制输出格式**（避免它回答得太啰嗦）  
✅ **给例子**（少样本学习，效果更好）

---

## 7. ⚠️ 注意事项

1. **幻觉问题**：模型可能自信地说错话  
	- 👉 解决：要求它"不知道就说不知道"
2. **成本考虑**：
    - 开源模型（FLAN-T5）：免费但需要GPU
    - 专有模型（GPT）：按使用量付费
3. **不是万能的**：  
	- 复杂任务还是建议用微调过的专用模型
