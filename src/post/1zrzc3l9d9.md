
# 名词解释：LLM、Transformer 架构、注意力机制、编码器与解码器、词云化、温度、图片词云

`#2025/07/24` `#ai` `#大模型开发`


## 目录
<!-- toc -->
 ## 1. 前置的名词解释 

![{%}|512](https://www.ituring.com.cn/figures/2025/AppGPT4ChatGPT2nd/003.jpg)

- NLP（自然语言处理，**Natural Language Processing**）：
	- 一种让`计算机`理解`人类自然语言`的技术
	- 实现 NLP 的途径之一是 `机器学习`
- **AI 定义**：人们认为它让计算机系统有能力执行那些通常需要人类智慧的任务
- **机器学习**：试图开发算法，使系统能够通过示例自己学习
-  **深度学习** （deep learning，DL） 是 `ML` 的一个分支
	- 专注于受**大脑结构**启发的算法
	- 这些算法被称为 **人工神经网络** （artificial neural network，`ANN`）
		- 它们可以处理大量的数据，并且在图像识别、语音识别及 NLP 等任务上表现出色。
- **GPT 模型的基础**是一种特定的神经网络架构，即 `Transformer`。
	- 2017 年，来自谷歌的 Vaswani 等人在论文“`Attention Is All You Need`”中提出了该架构。
	- `Transformer` 就像`阅读机`一样，它关注句子或段落的不同部分，以理解其上下文并产生连贯的回答。
	- 它还可以理解句子中的单词顺序和上下文意思
		- 这使得 `Transformer` 在语言翻译、问题回答和文本生成等任务中非常高效。

## 2. LLM

- LLM 即大语言模型

>  它就是一个读完了全互联网所有书的“超级输入法”，能根据你的前半句话，猜出概率最高的后半句话

## 3. 理解 `Transformer 架构`及其在 LLM 中的作用

### 3.1. 痛点：RNN 的线性瓶颈：

`RNN` 在处理较长文本时**容易遗忘前文内容**

- **串行处理限制：** RNN（及其变体 LSTM/GRU）必须按时间步（Time Step）顺序处理数据。$t$ 时刻的计算依赖于 $t-1$ 时刻的隐藏状态。
- **长距离依赖丢失 (Vanishing Gradient/Context)：** 随着序列长度增加，早期信息的权重在反向传播中逐渐衰减，导致模型“遗忘”上文。
- **计算效率低：** 无法充分并行化（Parallelization），训练大模型极慢。

### 3.2. 方案：Transformer 的架构

Transformer 抛弃了循环结构，完全基于 **Attention** 机制，实现了两个核心突破：

- **并行计算：** 输入序列的`所有 token` 被同时送入模型，不再依赖上一时刻的状态。
- **全局视野：** 任意两个 `token` 之间的距离都是 $O(1)$。无论序列多长，模型都能直接计算它们之间的关联，完美解决了长距离依赖问题。

### 3.3. 核心引擎：注意力机制 (Attention Mechanism)

- 之前：将文本序列中的所有单词视作`同等重要`
- 之后：`注意力机制`允许模型在每一步任务中“关注”**相关性最高的词**。

## 4. 注意力机制

### 4.1. 交叉注意力

以一个简单的句子翻译任务为例

#### 4.1.1. **场景**：机器翻译任务（Seq2Seq）

- **Source (Encoder 输入)**：`Alice enjoyed the sunny weather in Brussels`
- **Target (Decoder 生成)**：`Alice a profité du temps...` (待预测下一个词)

#### 4.1.2. 当前状态 (The State)

模型已经生成了法语句子的前半部分 `Alice a profité du temps`（Alice 享受了天气...），现在 `Decoder` 需要预测下一个形容词。

#### 4.1.3. 交叉注意力的运作 (The Mechanism)

此时，`Decoder` 的当前状态（Query）会去查询 `Encoder` 的所有输入 Token（Key/Value）。

- **权重分配 (Weight Assignment)**： 模型计算当前语境与源句子中每个单词的相关性（Attention Score）。
    - `sunny` & `weather` $\rightarrow$ **高权重** (High Attention)
        - _原因：这两个词直接定义了“天气”的属性，是当前翻译的核心线索。_
    - `Alice` & `Brussels` $\rightarrow$ **低权重** (Low Attention)
        - _原因：虽然是句子的一部分，但对于形容天气的词来说，人名和地点是无关噪声。_
- **聚焦 (Focusing)**： 这就好比打了一束**聚光灯**，在长长的源句中，只照亮了 `sunny weather` 这两个词。

#### 4.1.4. 预测结果 (The Output)

模型根据加权后的上下文信息，理解了这里需要一个表达“阳光明媚”的法语词汇。 $\rightarrow$ **最终输出 Token**：`ensoleillé`

![{%}|640](https://www.ituring.com.cn/figures/2025/AppGPT4ChatGPT2nd/004.jpg)

### 4.2. 自注意力

- 自注意力是指模型能够`自主关注输入文本中的不同部分`
- 在 NLP 中，自注意力机制使模型可以评估`句子中各个单词相`比于`其他单词`的重要性，从而更好地理解单词之间的关系，并能够综合多个单词的信息，构建更高层次的语义概念。
- 假设我们有这样一句话：“Alice received praise from her colleagues”（Alice 受到了同事们的称赞）
	- 如果模型试图理解句子中 `her` 的含义，自注意力机制会为句中的不同单词分配不同的权重，突出与 `her` 相关的重要单词。
	- 在这个例子中，`Alice` 和 `colleagues` 这两个单词与 `her` 关系密切，因此模型会为它们分配`更高的权重`。
	- 通过这种方式，自注意力机制帮助模型**建立新的语义概念**
		- 例如在本例中，它可能会形成“`Alice 的同事`”这一语义概念。如下图
		- 自注意力机制使新概念 `Alice's colleagues`（Alice 的同事）得以出现

![{%}|592](https://www.ituring.com.cn/figures/2025/AppGPT4ChatGPT2nd/005.jpg)

### 4.3. 自注意力机制 vs. 交叉注意力机制

- **自注意力机制**：
	- 让一个词在句子里自己找“队友”，看看谁和自己关系最密切。
	- 一个句子里的词自己互相“看”，搞清楚自己和其他词的关系。
	- 举例
		- 假设有一句话：**“我喜欢吃苹果。”**
			- “喜欢”这个词要理解它的意思，它可能会去“关注”句子里的“`我`”和“`苹果`”，因为它们和“`喜欢`”有关系。
			- 自注意力机制会帮每个词计算它和其他词的关联
				- 比如“喜欢”和“苹果”的关系可能很强，而“喜欢”和“吃”的关系可能稍弱。
- **交叉注意力机制**：
	- 让两个句子`互相“看”`，一个句子从另一个句子里找答案。
	- 两个句子`互相“看”`，一个句子从另一个句子里找信息。
	- 让两个不同的句子之间互相“看”，一个句子里的词去“关注”另一个句子里的词，搞清楚哪里有用的信息。
	- 举个例子
		- 把英文句子 **“I love apples”** 翻译成中文 **“我喜欢苹果”**。
			- 中文里的“`喜欢`”这个词需要“关注”英文里的“`love`”，因为它们是对应的
			- 中文的句子通过交叉注意力机制去“看”英文句子，找到翻译时需要的信息
- 应用场景区别
	- **自注意力**：用在理解一个句子，比如分析句子结构、词之间的关系。
	- **交叉注意力**：用在`翻译或对话`生成，一个句子需要从另一个句子里获取信息。

## 5. 并行架构

- 与循环架构不同`Transformer 架构`还具有易于`并行化`的优势。
- 这意味着 Transformer 架构可以`同时处理输入文本的多个部分`，而不是按顺序逐步处理（及串行）

## 6. 序列到序列 → 编码器 + 解码器

- Transformer 架构是一种`序列到序列`（sequence-to-sequence，`Seq2Seq`）的模型，**最初是为机器翻译等序列到序列任务而开发的**。
- 标准的 `Transformer` 架构有两个主要组件：
	- 编码器和解码器，二者都十分依赖`注意力机制`。
		- `编码器`的任务是处理输入文本，识别有价值的特征，并生成有意义的文本表示，称为 **嵌入** （embedding）。
			- **负责接收输入序列并生成上下文向量**（即对输入进行`编码`）
		- `解码器`使用这个`嵌入`来生成一个输出，比如翻译结果或摘要文本。这个输出有效地解释了编码信息。
			- 根据编码器生成的上下文向量以及自身的输入，生成输出序列（例如`翻译、文本生成`等）

### 6.1. GPT 不基于编码器

- GPT（Generative Pre-trained Transformer，生成式预训练 Transformer）是一类基于 Transformer 架构的模型，**专门利用原始架构中的解码器部分**
- 在 GPT 中，**不存在编码器**，因此无须通过`交叉注意力`机制来整合`编码器`产生的嵌入
- 也就是说，GPT 仅依赖解码器内部的**自注意力机制**来生成上下文感知的表示和预测结果
	-  GPT 和其他基于 Transformer 的模型（例如 BERT）的一个关键区别
		- BERT 等其他一些众所周知的模型是基于编码器的，

>  个人理解是，已经预训练了大量的向量空间世界，然后通过自己

### 6.2. 为什么 GPT 不使用编码器？只使用解码器？

- **任务需求**：
	- GPT 的核心任务是`生成文本`，而生成任务更适合`解码器架构`，`编码器`主要用于文本理解任务
- **效率考虑**：
	- `单向注意力机制`更适合生成任务，可以有效地预测下一个词，而`双向注意力`会增加计算复杂度
- **设计理念**：
	- GPT 的设计目标是构建一个`生成式模型`，而不是`理解式模型`

## 7. 解密 GPT 模型的词元化和预测步骤

LLM 接收提示词作为输入，并生成相应的文本，这个过程被称为 **文本补全** （text completion）。

例如，输入的提示词可能是“`The weather is nice today, so I decided to`”（今天天气很好，所以我决定去），而模型的输出则可能是“go for a walk.”（散步）。你可能会好奇 LLM 是如何根据提示词构建出这段文本的。实际上，这**主要是一个概率计算的问题**。

当 LLM 收到提示词之后，它首先将输入拆分成 **词元** （token）。这些词元代表单词、单词的一部分、空格或标点符号。比如，在前面的例子中，提示词可以被拆分成 `\[“The”,“wea”,“ther”,“is”,“nice”,“today”,“,”,“so”,“I”,“de”,“ci”,“ded”,“to”\]`。

几乎每个语言模型都配有自己的`分词器`。你可以在 OpenAI 平台上测试 GPT-3.5 和 GPT-4 系列的`分词器`。

>   - 对于英语文本，`100 个词元`大约等于 75 个`单词`
>   - 对于中文文本，`100 个词元`大约等于 50 ～ 80 个`汉字`（单词）。

因为有了注意力机制和 Transformer 架构，LLM 能够轻松处理词元并解释它们之间的关系及提示词的整体含义。Transformer 架构使模型能够高效地识别文本中的关键信息和上下文。

为了生成新的句子，LLM 会根据用户提供的提示词的上下文预测最有可能出现的后续词元。OpenAI 已经发布了多个版本的 GPT-4。
- 最初，用户可以选择的上下文窗口分别为 `8192` 个词元和 `32768` 个词元。
- 到 2024 年初，OpenAI 最新发布的模型是 GPT-4 Turbo 和 GPT-4o，其输入上下文窗口扩大到了 `128 000 个词元`，相当于`近 300 页的英文文本`。
- 与早期难以处理长输入序列的循环模型不同，Transformer 架构结合注意力机制，使得现代 LLM 能够将上下文作为一个整体来考虑。
- **模型为每个潜在的后续词元分配一个概率分数**，然后选择**概率最高的词元**作为序列中的下一个词元。
- 在前面的例子中，“The weather is nice today, so I decided to”之后，下一个最佳词元可能是“`go`”。

> 　可通过调整 **温度** （temperature）参数，模型可以不总是选择概率最高的下一个词，而是从一组高概率词中进行选择。这种机制允许模型在生成文本时引入一定的多样性和创造力，从而避免输出过于单一或机械化。

这一过程会不断重复，但**每次生成新词后，上下文也会随之扩展**。
- 例如，模型在第一步预测出“go”后，新的上下文变为“`The weather is nice today, so I decided to go`”，并将“go”作为新的输入的一部分。
- 接下来，模型可能会预测出“`for`”。这个过程会持续进行，直到生成完整的句子，例如“The weather is nice today, so I decided to go for a walk.”。
- 这一生成过程依赖于 LLM 从海量文本数据中学习出的可能性最高的下一个单词。图 1-5 直观地展示了这一过程。

![{%}|832](https://www.ituring.com.cn/figures/2025/AppGPT4ChatGPT2nd/007.jpg)

**图 1-5：逐词元地补全文本，整个过程是迭代式的**

## 8. 将视觉整合到 LLM 中

Transformer 是如何处理图像数据的。整体而言，这**与处理文本的方式非常相似**。

如前所述，当带有提示词的文本被发送到大模型时，大模型首先将文本分解为`小字符块`——词元，然后处理这些词元以预测下一个词元。在处理图像时，`ViT` 会首先将图像分割成固定大小的`图像块`（patch）。

下图展示了这一过程。

![{%}|824](https://www.ituring.com.cn/figures/2025/AppGPT4ChatGPT2nd/008.jpg)

**图 1-6：图像在输入到 Transformer 之前，被分割成固定大小的图像块**

这些图像块随后与文本词元整合到一个统一的输入序列中。简单来说，当 LLM 处理文本数据时，所有的`词元`都会首先被映射到一个高维空间。

换句话说，每个词元都会被转换成一个`高维向量`，而这种词元与高维向量之间的映射关系是在 LLM `训练过程中学习得出`的。

对于固定大小的图像块，处理方式几乎相同——模型在学习过程中计算出图像块与相同高维空间之间的映射函数。

通过这种映射，文本词元和图像块可以被放入相同的高维空间，形成一个融合的序列。

然后，这个包含文本和图像的输入序列会通过 `Transformer` 架构进行处理，以预测下一个`词元`。

由于可以在相同的高维表示空间中**整合文本词元和图像块**，模型能够在这两种模态之间应用`自注意力机制`，使其能够生成同时考虑文本和图像信息的响应。

