
# 关于 “LLM” 的演变、训练、应用与分类

`#2025/12/27` `#ai` 


## 目录
<!-- toc -->
 ## 1. “LLM”定义的演变 

- `Large` 只是相对的，也不能说`生成模型`才是 LLM，`表示模型`就不是

## 2. “LLM” 的训练范式

传统机器学习通常是为`特定任务（如分类）`训练模型。如图 1-29 所示，我们认为这是一个单步过程。

![{%}|632](https://www.ituring.com.cn/figures/2025/HandsonLLM/031.jpg)

> **图 1-29：传统机器学习是一个单步过程：为特定任务（如分类或回归）训练模型**

相比之下，创建 LLM 通常包含至少两个步骤。

### 2.1. 预训练：语言建模 

第一步称为 **预训练** ，占用了创建 LLM 过程中的大部分算力和训练时间。

LLM 在海量互联网文本语料库上进行训练，使模型能够学习语法、上下文和语言模式。

这个宽泛的训练阶段并不是针对特定任务或应用的，而仅`仅用于预测下一个词`。由此产生的模型通常被称为`基础模型或基座模型`。这些模型通常不会遵循指令。

### 2.2. 微调

第二步是 **微调** ，有时也称为 **后训练** （post-training），包括使用先前训练好的模型，并在更具体的任务上进行进一步训练。

这使得 LLM 能够适应特定任务或展现符合人们期望的行为。例如，我们可以`微调`一个基座模型，使其`在分类任务上表现良好或遵循指令`。

这可以节省大量资源，因为预训练阶段成本相当高，通常需要大多数人和组织难以企及的数据和计算资源。

对于任何经过第一步（预训练）的模型，我们都称之为`预训练模型`，这也包括`经过微调的模型`。这种两步训练方法如图 1-30 所示。

![{%}|664](https://www.ituring.com.cn/figures/2025/HandsonLLM/032.jpg)

**图 1-30：与传统机器学习相比，LLM 训练采用多步方法**

## 3. LLM 的应用

借助文本生成能力和提示词，LLM 适用于`广泛的任务`，似乎限制它应用范围的`只有人的想象力`。让我们探索一些常见任务和技术来说明这一点。

- 检测客户评论是正面的还是负面的
- 开发一个系统，找出主题相同的工单问题
- 构建一个用于检索和查看`相关文档`的系统
- 构建一个能利用外部资源（如工具和文档）的 LLM 聊天机器人
- 构建一个`能够根据冰箱中的食材图片`生成食谱的 LLM
	- **这个有想象力，如果真要做什么事情，就得做这种小众且有需求的**

创建 LLM 应用是极具吸引力的，因为在一定程度上，这些应用的能力仅仅受限于你的想象力。随着这些模型变得更加准确，我们将能够把模型应用于各种创新的场景，例如角色扮演和编写儿童读物，这将十分有趣。

## 4. 开发和使用`负责任`的 LLM

关键词：
- 监管
- 偏见和公平性
- 透明度和问责制
- 有害内容：
	- LLM 生成的内容不一定是真实的，且它们可能“自信地”输出错误的文本
- 知识产权

## 5. 有限的资源就够了

本书正是为“`GPU 穷人`”写的。我们将使用那些不需要最昂贵的 GPU 或高昂的预算就能运行的模型。

为此，我们会在 `Google Colab 实例`中提供所有代码。在撰写本书时，免费的 Google Colab 实例提供了带有 16 GB 显存的 T4 GPU，这是我们建议的最低显存容量。

## 6. 分类

### 6.1. 专有模型、闭源模型

比如 OpenAI 的 GPT-4 和 Anthropic 的 Claude。

![{%}|576](https://www.ituring.com.cn/figures/2025/HandsonLLM/033.jpg)

### 6.2. 开源模型

- 比如 Meta 的 Llama 系列模型都是开源模型
- 阿里的千问
- deepseek 等

只要你有能够处理这类模型的强大 GPU，就可以下载这些模型并在自己的设备上使用，如图 1-32 所示。

![{%}|624](https://www.ituring.com.cn/figures/2025/HandsonLLM/034.jpg)

**图 1-32：开源 LLM 由用户直接使用。因此，LLM 本身的细节（包括其代码和架构）都是与用户共享的**

- 本地模型的一个`主要优势`是用户可以`完全控制模型`。
- 你可以在不依赖 API 连接的情况下使用模型，对其进行`微调`，并通过它处理敏感数据。
- 你不依赖于任何服务，并且可以完全透明地了解模型产生输出的过程。
- 大型社区的支持进一步突出了这一优势，比如 `Hugging Face`，展示了基于开源模型开展社区合作的可能性。

开源 LLM 的一个缺点是你需要`强大的硬件`来运行，在`训练或微调`时甚至需要更强大的硬件。

此外，配置和使用这些模型需要`特定的知识`（我们将在本书中详细介绍）

我们通常倾向于尽可能使用开源 LLM。这种方式带来了更高的自由度，可以尝试各种选项、探索模型的内部工作原理以及本地使用模型，可以说，比使用闭源 LLM 好处更多。

### 6.3. 开源框架

 - 偏后端的
	 - llama.cpp、LangChain，以及许多框架的核心 Hugging Face Transformers。
 - 又比如有 GUI 的
	 - text-generation-webui、KoboldCpp 和 LM Studio。
