
# é¢å‘å‰ç«¯çš„ python æŒ‡å— 03ï¼šæ–‡æœ¬åˆ†è¯ï¼ˆTokenizationï¼‰


`#2026/01/04` `#python` 


## ç›®å½•
<!-- toc -->
 ## ğŸ“ åŠŸèƒ½è¯´æ˜ 

å°†åŸå§‹æ–‡æœ¬åˆ†å‰²æˆç‹¬ç«‹çš„ tokensï¼ˆå•è¯/æ ‡ç‚¹ç¬¦å·ï¼‰ï¼Œè¿™æ˜¯ NLP å’Œ LLM è®­ç»ƒçš„åŸºç¡€æ­¥éª¤ã€‚

```python
"""
æ­¥éª¤ 3: åˆ†è¯ (Tokenization)
åŠŸèƒ½: å°†æ–‡æœ¬åˆ†å‰²æˆ tokens
"""

import re
from typing import List

def tokenize(raw_text: str) -> List[str]:
    """
    å°†æ–‡æœ¬åˆ†å‰²æˆ tokens

    å‚æ•°:
        raw_text: åŸå§‹æ–‡æœ¬å­—ç¬¦ä¸²

    è¿”å›:
        tokens: åˆ†è¯åçš„åˆ—è¡¨
    """

    print("æ­£åœ¨è¿›è¡Œåˆ†è¯...")

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œåˆ†è¯
    preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', raw_text)

    # æ¸…ç†åˆ†è¯ç»“æœï¼š
    # - item.strip(): å»é™¤æ¯ä¸ª token ä¸¤ç«¯çš„ç©ºç™½å­—ç¬¦
    # - if item.strip(): è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²ï¼ˆåªåŒ…å«ç©ºç™½çš„é¡¹ï¼‰
    tokens = [item.strip() for item in preprocessed if item.strip()]

    print(f"âœ“ åˆ†è¯å®Œæˆï¼")
    print(f"  æ€» token æ•°: {len(tokens)}")
    print(f"  å‰ 50 ä¸ª tokens:")

    # æ‰“å°å‰ 50 ä¸ª tokensï¼Œæ¯è¡Œ 10 ä¸ª
    for i in range(0, min(50, len(tokens)), 10):
        batch = tokens[i : i + 10]
        print(f"    [{i:3d}-{i + len(batch) - 1:3d}] {batch}")

    return tokens

if __name__ == "__main__":
    print("=" * 60)
    print("æ­¥éª¤ 3: åˆ†è¯")
    print("=" * 60)

    # å¯¼å…¥æ­¥éª¤ 2 çš„å‡½æ•°
    from read_file import read_file

    # è¯»å–æ–‡ä»¶
    raw_text = read_file()
    print()

    # è¿›è¡Œåˆ†è¯
    tokens = tokenize(raw_text)

    print("\n" + "=" * 60)
    print("æ­¥éª¤ 3 å®Œæˆï¼")
    print("=" * 60)
```

---

## ğŸ” æ ¸å¿ƒæ¦‚å¿µ

### 1. æ­£åˆ™è¡¨è¾¾å¼ï¼ˆRegular Expressionï¼‰

#### Python å®ç°

```python
import re

# ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ–‡æœ¬
preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', raw_text)
```

#### JavaScript ç­‰ä»·å®ç°

```javascript
// JavaScript æ­£åˆ™è¡¨è¾¾å¼
const preprocessed = raw_text.split(/([,.:;?_!"()\']|--|\s)/);
```

**æ­£åˆ™è¡¨è¾¾å¼è¯¦è§£ï¼š**

```python
import re

# æ¨¡å¼åˆ†è§£
pattern = r'([,.:;?_!"()\']|--|\s)'
#         ^^^^^^^^^^^^^^^^     ^   ^
#         â‘ å­—ç¬¦ç±»/æ•è·ç»„    â‘¡å­—ç¬¦ä¸² â‘¢å­—ç¬¦ç±»

# â‘  [,.:;?_!"()\'] - å­—ç¬¦ç±»ï¼ˆCharacter Classï¼‰
# åŒ¹é…æ–¹æ‹¬å·å†…çš„ä»»æ„ä¸€ä¸ªå­—ç¬¦
# åŒ…æ‹¬ï¼šé€—å·ã€å¥å·ã€å†’å·ã€åˆ†å·ã€é—®å·ã€ä¸‹åˆ’çº¿ã€æ„Ÿå¹å·ã€åŒå¼•å·ã€å•å¼•å·ã€æ‹¬å·

# â‘¡ |-- - åŒ¹é…åŒè¿å­—ç¬¦
# æˆ–è¿ç®—ç¬¦

# â‘¢ \s - åŒ¹é…ä»»æ„ç©ºç™½å­—ç¬¦
# åŒ…æ‹¬ï¼šç©ºæ ¼ã€åˆ¶è¡¨ç¬¦(\t)ã€æ¢è¡Œç¬¦(\n)ã€å›è½¦ç¬¦(\r)

# (...) - æ•è·ç»„
# æ‹¬å·å†…çš„å†…å®¹ä¼šè¢«ä¿ç•™åœ¨ç»“æœä¸­
```

**æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼ï¼š**

```python
import re

text = "Hello, world! How are you?"

# ä¸ä½¿ç”¨æ•è·ç»„ï¼ˆåˆ†éš”ç¬¦ä¼šä¸¢å¤±ï¼‰
tokens1 = re.split(r'[,.:;?_!"()\']|--|\s', text)
print(tokens1)
# ['Hello', '', 'world', '', 'How', 'are', 'you', '']
# æ³¨æ„ï¼šç©ºå­—ç¬¦ä¸²å’Œåˆ†éš”ç¬¦éƒ½ä¸¢å¤±äº†

# ä½¿ç”¨æ•è·ç»„ï¼ˆä¿ç•™åˆ†éš”ç¬¦ï¼‰
tokens2 = re.split(r'([,.:;?_!"()\']|--|\s)', text)
print(tokens2)
# ['Hello', ', ', 'world', '! ', 'How', ' ', 'are', ' ', 'you', '?']
# åˆ†éš”ç¬¦è¢«ä¿ç•™

# å¯¹æ¯” JavaScript
// JavaScript
const text = "Hello, world! How are you?";
const tokens = text.split(/([,.:;?_!"()\']|--|\s)/);
console.log(tokens);
// ['Hello', ', ', 'world', '! ', 'How', ' ', 'are', ' ', 'you', '?', '']
```

---

### 2. re æ¨¡å—æ ¸å¿ƒæ–¹æ³•

> [!success] æ€»ç»“
> - sub â†’ replace
> - split â†’ split
> - findAll â†’ macth g

#### Python å®ç°

```python
import re

text = "Hello, world! 123"

# re.split - åˆ†å‰²
re.split(r',\s*', text)  # ['Hello', 'world! 123']

# re.findall - æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
re.findall(r'\d+', text)  # ['123']

# re.sub - æ›¿æ¢
re.sub(r'world', 'Python', text)  # 'Hello, Python! 123'

# re.match - ä»å¼€å¤´åŒ¹é…
re.match(r'Hello', text)  # <match object>
re.match(r'world', text)  # None

# re.search - æœç´¢ç¬¬ä¸€ä¸ªåŒ¹é…
re.search(r'world', text)  # <match object>

# re.compile - ç¼–è¯‘æ­£åˆ™ï¼ˆæé«˜æ€§èƒ½ï¼‰
pattern = re.compile(r'\d+')
pattern.findall(text)  # ['123']
```

#### JavaScript ç­‰ä»·å®ç°

```javascript
const text = "Hello, world! 123";

// split - åˆ†å‰²
text.split(/,\s*/)  // ['Hello', 'world! 123']

// match - æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
text.match(/\d+/g)  // ['123']

// replace - æ›¿æ¢
text.replace(/world/g, 'Python')  // 'Hello, Python! 123'

// match - ä»å¼€å¤´åŒ¹é…
text.match(/^Hello/)  // ['Hello', index: 0, ...]
text.match(/^world/)  // null

// search - æœç´¢ç¬¬ä¸€ä¸ªåŒ¹é…
text.search(/world/)  // 7ï¼ˆç´¢å¼•ä½ç½®ï¼‰

// æ— éœ€ç¼–è¯‘ï¼Œæ­£åˆ™è¡¨è¾¾å¼å­—é¢é‡å³ç¼–è¯‘å½¢å¼
```

**å¯¹æ¯”è¡¨ï¼š**

| æ“ä½œ | Python | JavaScript |
|------|--------|-----------|
| åˆ†å‰² | `re.split(pattern, text)` | `text.split(pattern)` |
| æŸ¥æ‰¾ | `re.findall(pattern, text)` | `text.match(pattern)`ï¼ˆéœ€ `/g`ï¼‰ |
| æ›¿æ¢ | `re.sub(pattern, repl, text)` | `text.replace(pattern, repl)` |
| æœç´¢ | `re.search(pattern, text)` | `text.search(pattern)` |
| ç¼–è¯‘ | `re.compile(pattern)` | æ­£åˆ™å­—é¢é‡ `/.../` |

---

### 3. åˆ—è¡¨æ¨å¯¼å¼ï¼ˆList Comprehensionï¼‰

> å¦å¤–å¯å‚è€ƒ [5. Python å­—å…¸æ¨å¯¼å¼ä¸ enumerate ç”¨æ³•è¯¦è§£](/post/vzrcmybi1t.html)

#### Python å®ç°

```python
tokens = [item.strip() for item in preprocessed if item.strip()]
```

#### JavaScript ç­‰ä»·å®ç°

```javascript hl:2
// ä½¿ç”¨ map + filter
const tokens = preprocessed
  .map(item => item.trim())
  .filter(item => item.length > 0);

// æˆ–ä½¿ç”¨ flatMapï¼ˆæ›´é«˜æ•ˆï¼‰
const tokens = preprocessed
  .flatMap(item => {
    const trimmed = item.trim();
    return trimmed ? [trimmed] : [];
  });
```

**åˆ—è¡¨æ¨å¯¼å¼è¯­æ³•ï¼š**

```python hl:19,2
# åŸºæœ¬è¯­æ³•
# [è¡¨è¾¾å¼ for å˜é‡ in å¯è¿­ä»£å¯¹è±¡ if æ¡ä»¶]

# ç¤ºä¾‹ 1: åŸºæœ¬åˆ—è¡¨æ¨å¯¼
numbers = [1, 2, 3, 4, 5]
squares = [x**2 for x in numbers]  # è®¡ç®—æ¯ä¸ªæ•°å­—çš„å¹³æ–¹
# ç»“æœ: [1, 4, 9, 16, 25]

# JavaScript ç­‰ä»·
const squares = numbers.map(x => x**2); // è®¡ç®—æ¯ä¸ªæ•°å­—çš„å¹³æ–¹

# ç¤ºä¾‹ 2: å¸¦è¿‡æ»¤
evens = [x for x in numbers if x % 2 == 0]  # ç­›é€‰å‡ºå¶æ•°
# ç»“æœ: [2, 4]

# JavaScript ç­‰ä»·
const evens = numbers.filter(x => x % 2 === 0); // ç­›é€‰å‡ºå¶æ•°

# ç¤ºä¾‹ 3: å¸¦æ¡ä»¶è¡¨è¾¾å¼ â†’ ä¸‰å…ƒè¡¨è¾¾å¼
result = [(x if x > 0 else -x) for x in numbers]  # å°†æ­£æ•°ä¿æŒä¸å˜ï¼Œè´Ÿæ•°å–å…¶ç›¸åæ•°
# ç»“æœ: [1, 2, 3, 4, 5]

# JavaScript ç­‰ä»·
const result = numbers.map(x => x > 0 ? x : -x); // å°†æ­£æ•°ä¿æŒä¸å˜ï¼Œè´Ÿæ•°å–å…¶ç›¸åæ•°

```

**å¤æ‚çš„åˆ—è¡¨æ¨å¯¼å¼ï¼š**

```python
# åµŒå¥—å¾ªç¯
matrix = [1, 2, 3], [4, 5, 6], [7, 8, 9](/post/hzlaypj4lb.html#1,-2,-3],-[4,-5,-6],-[7,-8,-9)
flattened = [x for row in matrix for x in row]
# [1, 2, 3, 4, 5, 6, 7, 8, 9]

# JavaScript ç­‰ä»·
const flattened = matrix.flat();

# å¸¦ç´¢å¼•
words = ['apple', 'banana', 'cherry']
indexed = [(i, word) for i, word in enumerate(words)]
# [(0, 'apple'), (1, 'banana'), (2, 'cherry')]

# JavaScript ç­‰ä»·
const indexed = words.map((word, i) => [i, word]);
```

**ä»£ç è§£æï¼ˆæˆ‘ä»¬çš„ä¾‹å­ï¼‰ï¼š**

```python
tokens = [item.strip() for item in preprocessed if item.strip()]

# åˆ†è§£æ­¥éª¤ï¼š
# 1. for item in preprocessed - éå†åˆ—è¡¨
# 2. if item.strip() - è¿‡æ»¤æ¡ä»¶ï¼ˆåªä¿ç•™éç©ºï¼‰
# 3. item.strip() - æ˜ å°„æ“ä½œï¼ˆå»é™¤ç©ºç™½ï¼‰

# ç­‰ä»·äºä»¥ä¸‹ä»£ç ï¼š
tokens = []
for item in preprocessed:
    if item.strip():  # æ£€æŸ¥å»é™¤ç©ºç™½åæ˜¯å¦éç©º
        tokens.append(item.strip())

# JavaScript ç­‰ä»·
const tokens = preprocessed
  .filter(item => item.trim().length > 0)
  .map(item => item.trim());
```

---

### 4. å­—ç¬¦ä¸²æ–¹æ³•ï¼ˆstripï¼‰

#### Python å®ç°

```python hl:6,10,14
text = "  Hello, World!  "

# strip() - å»é™¤ä¸¤ç«¯ç©ºç™½
text.strip()  # "Hello, World!"

# lstrip() - å»é™¤å·¦ç«¯ç©ºç™½
text.lstrip()  # "Hello, World!  "

# rstrip() - å»é™¤å³ç«¯ç©ºç™½
text.rstrip()  # "  Hello, World!"

# å»é™¤ç‰¹å®šå­—ç¬¦
text = "***Hello***"
text.strip('*')  # "Hello"
```

#### JavaScript ç­‰ä»·å®ç°

```javascript
const text = "  Hello, World!  ";

// trim() - å»é™¤ä¸¤ç«¯ç©ºç™½
text.trim();  // "Hello, World!"

// trimStart() / trimLeft() - å»é™¤å·¦ç«¯ç©ºç™½
text.trimStart();  // "Hello, World!  "

// trimEnd() / trimRight() - å»é™¤å³ç«¯ç©ºç™½
text.trimEnd();  // "  Hello, World!"

// å»é™¤ç‰¹å®šå­—ç¬¦ï¼ˆéœ€è¦æ­£åˆ™ï¼‰
const text2 = "***Hello***";
text2.replace(/^\*+|\*+$/g, '');  // "Hello"
```

**å¯¹æ¯”è¡¨ï¼š**

| æ“ä½œ | Python | JavaScript |
|------|--------|-----------|
| å»é™¤ä¸¤ç«¯ç©ºç™½ | `.strip()` | `.trim()` |
| å»é™¤å·¦ç«¯ç©ºç™½ | `.lstrip()` | `.trimStart()` / `.trimLeft()` |
| å»é™¤å³ç«¯ç©ºç™½ | `.rstrip()` | `.trimEnd()` / `.trimRight()` |
| å»é™¤æŒ‡å®šå­—ç¬¦ | `.strip('*')` | `.replace(/^\*+|\*+$/g, '')` |

---

### 5. range() å‡½æ•°

#### Python å®ç°

```python
# æ‰“å°å‰ 50 ä¸ª tokensï¼Œæ¯è¡Œ 10 ä¸ª
for i in range(0, min(50, len(tokens)), 10):
    batch = tokens[i:i+10]
    print(f"    [{i:3d}-{i+len(batch)-1:3d}] {batch}")
```

#### JavaScript ç­‰ä»·å®ç°

```javascript
// JavaScript æ²¡æœ‰ç›´æ¥çš„ range å‡½æ•°
for (let i = 0; i < Math.min(50, tokens.length); i += 10) {
  const batch = tokens.slice(i, i + 10);
  console.log(`[${i}-${i + batch.length - 1}] ${batch}`);
}

// æˆ–ä½¿ç”¨ Array.from
const indices = Array.from(
  {length: Math.ceil(Math.min(50, tokens.length) / 10)},
  (_, k) => k * 10
);
```

**range() è¯¦è§£ï¼š**

```python hl:7
# range(stop) - 0 åˆ° stop-1
list(range(5))  # [0, 1, 2, 3, 4]

# range(start, stop) - start åˆ° stop-1
list(range(2, 5))  # [2, 3, 4]

# range(start, stop, step) - å¸¦æ­¥é•¿
list(range(0, 10, 2))  # [0, 2, 4, 6, 8]

# è´Ÿæ­¥é•¿ï¼ˆå€’åºï¼‰
list(range(10, 0, -1))  # [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]

# range vs JavaScript
// JavaScript: ä½¿ç”¨ for...of æˆ–æ‰©å±•è¿ç®—ç¬¦
[...Array(5).keys()]  // [0, 1, 2, 3, 4]

Array.from({length: 5}, (_, i) => i)  // [0, 1, 2, 3, 4]
```

---

### 6. åˆ—è¡¨åˆ‡ç‰‡ï¼ˆSlicingï¼‰

#### Python å®ç°

```python
batch = tokens[i:i+10]
# tokens[0:10]   # å‰ 10 ä¸ªå…ƒç´ 
# tokens[10:20]  # ç¬¬ 10-19 ä¸ªå…ƒç´ 
# tokens[-10:]   # æœ€å 10 ä¸ªå…ƒç´ 
```

#### JavaScript ç­‰ä»·å®ç°

```javascript
const batch = tokens.slice(i, i + 10);
// tokens.slice(0, 10)   // å‰ 10 ä¸ªå…ƒç´ 
// tokens.slice(10, 20)  // ç¬¬ 10-19 ä¸ªå…ƒç´ 
// tokens.slice(-10)     // æœ€å 10 ä¸ªå…ƒç´ 
```

**Python åˆ‡ç‰‡ vs JavaScript sliceï¼š**

```python hl:11
# Python åˆ‡ç‰‡è¯­æ³•
tokens[start:stop:step]

# ç¤ºä¾‹
tokens = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

tokens[2:5]    # [2, 3, 4]
tokens[:5]     # [0, 1, 2, 3, 4]
tokens[5:]     # [5, 6, 7, 8, 9]
tokens[::2]    # [0, 2, 4, 6, 8] (å¶æ•°)
tokens[::-1]   # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] (åè½¬)

# JavaScript
const tokens = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];

tokens.slice(2, 5);  // [2, 3, 4]
tokens.slice(0, 5);  // [0, 1, 2, 3, 4]
tokens.slice(5);    // [5, 6, 7, 8, 9]
tokens.filter((_, i) => i % 2 === 0);  // [0, 2, 4, 6, 8] (å¶æ•°)
tokens.slice().reverse();  // [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] (åè½¬)
```

---

### 7. f-string æ ¼å¼åŒ–è¿›é˜¶

#### Python å®ç°

```python
print(f"    [{i:3d}-{i+len(batch)-1:3d}] {batch}")
#          ^^^  ^^^^^^^^^^^^^^
#          æ ¼å¼è¯´æ˜ç¬¦
```

**æ ¼å¼è¯´æ˜ç¬¦è¯¦è§£ï¼š**

```python
# è¯­æ³•ï¼š{å˜é‡:å®½åº¦.ç²¾åº¦ç±»å‹}

# æ•°å­—
num = 42
f"{num}"      # "42"
f"{num:5d}"   # "   42" (å³å¯¹é½ï¼Œå®½åº¦ 5)
f"{num:05d}"  # "00042" (è¡¥é›¶)
f"{num:<5d}"  # "42   " (å·¦å¯¹é½)
f"{num:^5d}"  # " 42  " (å±…ä¸­)

# æµ®ç‚¹æ•°
pi = 3.14159
f"{pi:.2f}"   # "3.14" (ä¿ç•™ 2 ä½å°æ•°)
f"{pi:10.2f}" # "      3.14" (å®½åº¦ 10ï¼Œ2 ä½å°æ•°)

# å­—ç¬¦ä¸²
name = "Alice"
f"{name:>10}" # "     Alice" (å³å¯¹é½)
f"{name:<10}" # "Alice     " (å·¦å¯¹é½)
f"{name:^10}" # "  Alice   " (å±…ä¸­)

# åˆ—è¡¨
batch = ['a', 'b', 'c']
f"{batch}"    # "['a', 'b', 'c']"
```

#### JavaScript ç­‰ä»·å®ç°

```javascript
// JavaScript æ²¡æœ‰å†…ç½®æ ¼å¼åŒ–ï¼Œéœ€è¦æ‰‹åŠ¨å®ç°
const num = 42;
console.log(`    ${num}`);  // "    42"

// æˆ–ä½¿ç”¨ padStart
num.toString().padStart(5, ' ');  // "   42"

// æ ¼å¼åŒ–æ•°å­—ï¼ˆIntl.NumberFormatï¼‰
const pi = 3.14159;
new Intl.NumberFormat('en-US', {
  minimumFractionDigits: 2,
  maximumFractionDigits: 2
}).format(pi);  // "3.14"
```

---

### 8. ç±»å‹æç¤ºï¼ˆType Hintsï¼‰

#### Python å®ç°

```python
from typing import List

def tokenize(raw_text: str) -> List[str]:
    """
    å°†æ–‡æœ¬åˆ†å‰²æˆ tokens

    å‚æ•°:
        raw_text: åŸå§‹æ–‡æœ¬å­—ç¬¦ä¸²

    è¿”å›:
        tokens: åˆ†è¯åçš„åˆ—è¡¨
    """
    pass
```

#### TypeScript ç­‰ä»·å®ç°

```typescript
function tokenize(rawText: string): string[] {
  /**
   * å°†æ–‡æœ¬åˆ†å‰²æˆ tokens
   *
   * @param rawText åŸå§‹æ–‡æœ¬å­—ç¬¦ä¸²
   * @returns åˆ†è¯åçš„åˆ—è¡¨
   */
  const tokens: string[] = [];
  return tokens;
}
```

**Python ç±»å‹æç¤ºè¯¦è§£ï¼š**

```python
from typing import List, Dict, Tuple, Optional, Union

# åŸºæœ¬ç±»å‹
def func1(x: int, y: str) -> bool:
    return True

# åˆ—è¡¨
def func2() -> List[str]:
    return ["a", "b", "c"]

# å­—å…¸
def func3() -> Dict[str, int]:
    return {"a": 1, "b": 2}

# å…ƒç»„
def func4() -> Tuple[int, str, float]:
    return (1, "hello", 3.14)

# å¯é€‰ç±»å‹
def func5() -> Optional[str]:
    return None  # æˆ–è¿”å›å­—ç¬¦ä¸²

# è”åˆç±»å‹
def func6() -> Union[int, str]:
    return 42  # æˆ–è¿”å›å­—ç¬¦ä¸²

# Python 3.10+ ç®€åŒ–è¯­æ³•
def func6() -> int | str:
    return 42

# æ³›å‹ï¼ˆPython 3.12+ï¼‰
from typing import TypeVar

T = TypeVar('T')

def get_first(items: List[T]) -> T:
    return items[0]
```

---

## ğŸ¯ Python æœ€ä½³å®è·µ

### 1. æ­£åˆ™è¡¨è¾¾å¼æ€§èƒ½ä¼˜åŒ–

```python hl:4
# âœ… æ¨èï¼šé¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
import re

TOKEN_PATTERN = re.compile(r'([,.:;?_!"()\']|--|\s)')

def tokenize(text: str) -> List[str]:
    return TOKEN_PATTERN.split(text)

# âŒ ä¸æ¨èï¼šæ¯æ¬¡è°ƒç”¨éƒ½ç¼–è¯‘
def tokenize(text: str) -> List[str]:
    return re.split(r'([,.:;?_!"()\']|--|\s)', text)
```

### 2. åˆ—è¡¨æ¨å¯¼å¼ vs ç”Ÿæˆå™¨è¡¨è¾¾å¼

```python hl:4
# åˆ—è¡¨æ¨å¯¼å¼ - ç«‹å³åˆ›å»ºåˆ—è¡¨
tokens = [item.strip() for item in items if item.strip()]

# ç”Ÿæˆå™¨è¡¨è¾¾å¼ - æƒ°æ€§æ±‚å€¼ï¼ˆèŠ‚çœå†…å­˜ï¼‰
tokens_gen = (item.strip() for item in items if item.strip())

# ä½¿ç”¨ç”Ÿæˆå™¨
for token in tokens_gen:
    print(token)

# è½¬æ¢ä¸ºåˆ—è¡¨
tokens_list = list(tokens_gen)
```

### 3. ä½¿ç”¨å‘½åå…ƒç»„æé«˜å¯è¯»æ€§

```python hl:3
from typing import NamedTuple

class Token(NamedTuple):
    text: str
    start: int
    end: int

# ä½¿ç”¨
token = Token("hello", 0, 5)
print(token.text)   # "hello"
print(token.start)  # 0
print(token.end)    # 5
```

---

## ğŸ“š æ·±å…¥ç†è§£ï¼šåˆ†è¯ç­–ç•¥

### å¸¸è§åˆ†è¯æ–¹æ³•å¯¹æ¯”

```python hl:10
# 1. ç©ºæ ¼åˆ†è¯ï¼ˆæœ€ç®€å•ï¼‰
text = "Hello, world!"
tokens1 = text.split()  # ['Hello,', 'world!']

# 2. æ­£åˆ™åˆ†è¯ï¼ˆæœ¬é¡¹ç›®ä½¿ç”¨ï¼‰
import re
tokens2 = re.split(r'([,.:;?_!"()\']|--|\s)', text)
# ['Hello', ', ', 'world', '!', '']

# 3. NLTK åˆ†è¯å™¨
import nltk
tokens3 = nltk.word_tokenize(text)
# ['Hello', ',', 'world', '!']

# 4. spaCy åˆ†è¯å™¨
import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp(text)
tokens4 = [token.text for token in doc]
# ['Hello', ',', 'world', '!']

# 5. BPEï¼ˆå­—èŠ‚å¯¹ç¼–ç ï¼ŒGPT ä½¿ç”¨ï¼‰
# éœ€è¦è®­ç»ƒï¼Œèƒ½å¤„ç†æœªçŸ¥è¯
```

---

## ğŸ”„ Python vs JavaScript å®Œæ•´å¯¹æ¯”

### åˆ†è¯å‡½æ•°å®Œæ•´å®ç°

#### Python

```python
import re
from typing import List

def tokenize(raw_text: str) -> List[str]:
    """åŒæ­¥åˆ†è¯"""
    preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', raw_text)
    tokens = [item.strip() for item in preprocessed if item.strip()]
    return tokens

# ä½¿ç”¨
text = "Hello, world!"
tokens = tokenize(text)
```

#### JavaScript

```javascript
function tokenize(text) {
  // åŒæ­¥åˆ†è¯
  const preprocessed = text.split(/([,.:;?_!"()\']|--|\s)/);
  const tokens = preprocessed
    .map(item => item.trim())
    .filter(item => item.length > 0);
  return tokens;
}

// ä½¿ç”¨
const text = "Hello, world!";
const tokens = tokenize(text);
```

---

## ğŸš€ å®æˆ˜ç»ƒä¹ 

### ç»ƒä¹  1ï¼šè‡ªå®šä¹‰åˆ†è¯å™¨

```python
import re
from typing import List

class CustomTokenizer:
    def __init__(self, pattern: str):
        self.pattern = re.compile(pattern)

    def tokenize(self, text: str) -> List[str]:
        tokens = self.pattern.split(text)
        return [t.strip() for t in tokens if t.strip()]

# ä½¿ç”¨
tokenizer = CustomTokenizer(r'([,.:;?_!"()\']|--|\s)')
tokens = tokenizer.tokenize("Hello, world!")
```

### ç»ƒä¹  2ï¼šæ·»åŠ ç‰¹æ®Šæ ‡è®°

```python
def tokenize_with_special(text: str) -> List[str]:
    """æ·»åŠ  <BOS> <EOS> æ ‡è®°"""
    tokens = tokenize(text)
    return ['<BOS>'] + tokens + ['<EOS>']

# ä½¿ç”¨
tokens = tokenize_with_special("Hello world")
# ['<BOS>', 'Hello', 'world', '<EOS>']
```

---

## ğŸ“š æ€»ç»“

**å…³é”®è¦ç‚¹ï¼š**

1. âœ… **æ­£åˆ™è¡¨è¾¾å¼** - å¼ºå¤§çš„æ–‡æœ¬åŒ¹é…å·¥å…·
2. âœ… **åˆ—è¡¨æ¨å¯¼å¼** - Pythonic çš„æ•°æ®å¤„ç†æ–¹å¼
3. âœ… **ç±»å‹æç¤º** - æé«˜ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§
4. âœ… **re æ¨¡å—** - Python çš„æ­£åˆ™è¡¨è¾¾å¼åº“
5. âœ… **å­—ç¬¦ä¸²æ–¹æ³•** - `.strip()` æ¸…ç†ç©ºç™½

**Python vs JavaScriptï¼š**
- æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•å‡ ä¹ç›¸åŒ
- Python ä½¿ç”¨ `re` æ¨¡å—ï¼ŒJavaScript ä½¿ç”¨æ­£åˆ™å­—é¢é‡
- Python æœ‰åˆ—è¡¨æ¨å¯¼å¼ï¼ŒJavaScript ä½¿ç”¨ `map`/`filter`
